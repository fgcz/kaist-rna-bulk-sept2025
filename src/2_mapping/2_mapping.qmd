---
title: "Part 2: Mapping"
format:
  html:
    embed-resources: true
    toc: true
    toc-location: left
    toc-depth: 3
    title-block-banner: "#00A7FF"
css: style.css
editor: visual
bibliography: references.bib
---

# Mapping with STAR

For this section, we will be aligning our processed fastqs using STAR [@dobin2012] and looking at the alignments in IGV.

## Exploring test data

First, let's look at our test data for this section: fastp-processed files based on the subsampled data from the previous section to speed up alignment.

Now that the data has been downloaded, let's see exactly what we are dealing with. To this end, run the following cell. It calls [seqkit](https://bioinf.shenwei.me/seqkit/usage/) to output some stats about the fastq files about the cell-line HCT116 samples.

```{bash}
#| class-output: scrolling

echo "Running on raw fastqs..."
seqkit stats --skip-err --quiet ~/work/gse154927-subsampled/fastq/HCT116*fastq.gz
echo
echo
echo "Running on trimmed/filtered fastqs..."
seqkit stats --skip-err --quiet ~/work/gse154927-subsampled/fastp/HCT116*fastq.gz
```

### Exercise #1

1.  How many reads does each sample have? How does this compare to the input fastq files? Hint: compare the read counts in the two subdirectories from `~/work/gse154927-subsampled`

2.  Is the minimum length of each read in the fastq files expected?

::: {.callout-tip collapse="true"}
## Solutions

```{r, warning=FALSE}
suppressPackageStartupMessages(library(tidyverse))

dat_raw <- vroom::vroom("~/work/gse154927-subsampled/fastq/dataset.tsv", show_col_types = FALSE) %>% arrange(Name)
dat_fastp <- vroom::vroom("~/work/gse154927-subsampled/fastp/dataset.tsv", show_col_types = FALSE) %>% arrange(Name)

tibble(Name=dat_raw$Name, OriginalCount=dat_raw$`Read Count`, FastpCount=dat_fastp$`Read Count`, ReadFraction=dat_fastp$`Read Count` / dat_raw$`Read Count`)
```

1.  As expected, each sample has around a tenth of the input reads of our initial sequencing data. 500'000 to 1'000'000 may seem like little considering the general recommendation of 20M for bulk RNA-seq, but we would likely still get somewhat usable count data from this assuming we mostly care about large fold changes.
2.  Yes, we specified a minimum length of 30bp when we ran fastp, which is what we see in the seqkit output.
:::

## Running STAR

We are now ready to run the STAR aligner on our inputs. Note that an import step has already been done for us, namely the creation of the STAR index directory. How to generate this directory be found [here](https://hbctraining.github.io/Intro-to-rnaseq-hpc-O2/lessons/03_alignment.html#running-star). Alignment with STAR can (despite its purported speed) take a while, around \~15 minutes for all samples, so look over commands in the meantime.

```{bash, eval=FALSE}
set +e

TRIMMED_FASTQS=~/work/gse154927-subsampled/fastp
OUTPUT_DIR=~/work/results/2_mapping/STAR_alignment
STAR_INDEX=~/work/grch38-p13-gencode-release-42/annotation/genes_STARIndex
GENES_BED=~/work/grch38-p13-gencode-release-42/annotation/genes.bed
mkdir -p $OUTPUT_DIR

ALL_SAMPLES=$(cat ~/work/gse154927-subsampled/fastp/dataset.tsv | awk -F"\t" '{print $1}' | tail +2 | sort)

# Start processing with fastp
for SN in $ALL_SAMPLES
  do echo $SN
  R1_FILE=$TRIMMED_FASTQS/"${SN}_R1.fastq.gz"
  R2_FILE=$TRIMMED_FASTQS/"${SN}_R2.fastq.gz"
  
  # First do alignment with STAR using a pre-built index
  time STAR \
	  --genomeDir $STAR_INDEX \
	  --readFilesIn $R1_FILE $R2_FILE \
	  --twopassMode None \
	  --runThreadN 4 \
	  --sjdbOverhang 150 \
	  --outFilterType BySJout \
	  --outFilterMatchNmin 30 \
	  --outFilterMismatchNmax 10 \
	  --outFilterMismatchNoverLmax 0.05 \
	  --outMultimapperOrder Random \
	  --alignSJDBoverhangMin 1 \
	  --alignSJoverhangMin 8 \
	  --alignIntronMax 100000 \
	  --alignMatesGapMax 100000  \
	  --outFilterMultimapNmax 50 \
	  --chimSegmentMin 15 \
	  --chimJunctionOverhangMin 15 \
	  --chimScoreMin 15 \
	  --chimScoreSeparation 10 \
	  --outSAMstrandField intronMotif \
	  --alignEndsProtrude 10 ConcordantPair \
	  --outSAMmultNmax 4 \
	  --outSAMattributes All  \
	  --outStd BAM_Unsorted \
	  --outSAMtype BAM Unsorted \
    --outSAMattrRGline ID:$SAMPLE_NAME SM:$SAMPLE_NAME \
    --readFilesCommand zcat > $OUTPUT_DIR/$SAMPLE_NAME.out.bam
  
  # Sort and index
  samtools sort -l 9 -m 2625M -@ 4 $OUTPUT_DIR/$SAMPLE_NAME.out.bam -o $OUTPUT_DIR/$SAMPLE_NAME.bam
  rm -f $OUTPUT_DIR/$SAMPLE_NAME.out.bam
  samtools index $OUTPUT_DIR/$SAMPLE_NAME.bam
  
  # “Guess” how RNA-seq sequencing were configured
  infer_experiment.py -r $GENES_BED \
    -i $OUTPUT_DIR/$SAMPLE_NAME.bam -s 200000 > $OUTPUT_DIR/$SAMPLE_NAME"_inferred.txt"
done
```

Let's first take a look at the outputs first. The above function ran STAR, sorted the bam output, indexed it, and ran a function to determine the strandedness of the inputs. Let's perform a quick exercise related to the plain text outputs generated by STAR.

### Exercise #2

1.  Take a look at the files ending in "\_Log.final.out". Which sample has the highest percentage of primary alignments? Which has the lowest percentage?
2.  What is the range of splices for the samples? Do you think these are real?
3.  (Challenge) Find the answers to the above two questions programmatically.
4.  We ran a python file called `infer_experiment.py`, which aims to infer the strandedness of bam alignments using a bed file for reference. These outputs were placed into the files ending in "\_inferred.txt". Is the predicted strandedness consistent with our expectations?

::: {.callout-tip collapse="true"}
## Solutions

Let's first answer number 3, as it will help us to answer the other questions. This is obviously not the only way to do this, so feel free to use your own (potenitally more efficient) solution.

```{r}
library(tidyverse)
starLogFiles <- Sys.glob("../../results/2_mapping/STAR_alignment/*_Log.final.out")
logFiles <- lapply(starLogFiles, function(x) {
  tmp <- data.table::fread(x, sep="|", strip.white=TRUE, nrows=9, skip=8) %>% 
    as.data.frame()
  tmpVals <- str_trim(tmp[,2])
  tmpNames <- tmp[,1]
  names(tmpVals) <- tmpNames
  return(as_tibble(as.list(tmpVals)))
}) %>% 
  bind_rows() %>%
  mutate(`Uniquely mapped reads %`=sub("%", "", `Uniquely mapped reads %`)) %>%
  mutate_all(., as.numeric)
logFiles$Names <- basename(starLogFiles)
summary(logFiles) # Solution to exercise 3
```

1.  G2 is the sample with the highest mapping rate. GE3 is the sample with the lowest mapping rate.
2.  1'702 to 6'585. Only a fraction of these splice sites are expected to be real considering the low frequency of splicing in yeast.
3.  (see code)
4.  Yes, the output is largely antisense.
:::

## Alignment QC

We have already performed a few QC steps in the above section. Let's now explore these outputs a bit further using the python-package [RSeQC](https://rseqc.sourceforge.net/). This package contains a number of useful standalone python scripts for running general QC of alignment data, with an emphasis on RNAseq data. In fact, we already used one of these scripts above to infer the strandedness of the experiment.

Only a handful of samples will be run for each program at a time to cut-down on processing time.

### TIN Score

First, let's calculate the TIN for a few samples. This score, short for *transcript integrity number*, is analogous to RIN and measures RNA integrity at the transcript level, rather than at the sample level. Each transcript gets an associated TIN score \$0 \leq TIN \leq 100\$. We can however also summarise these TIN scores across a sample by taking the median to get a sample-level quality measure.

```{bash}
PROJ_DIR=../../
OUTPUT_DIR=$PROJ_DIR/results/2_mapping/rseqc_analysis
BAM_DIR=$PROJ_DIR/results/2_mapping/STAR_alignment
mkdir -p $OUTPUT_DIR

for BAM_FILE in $BAM_DIR/GE2.bam $BAM_DIR/GE4.bam; do
  SAMPLE_NAME=$(basename ${BAM_FILE%.bam})
  echo $SAMPLE_NAME
  
  tin.py -r $PROJ_DIR/data/supplementary-files/Ensembl_R64_genes/genes.bed \
    -i $BAM_FILE 2> $OUTPUT_DIR/$SAMPLE_NAME".tin.err"
  mv ./$SAMPLE_NAME".tin.xls" $OUTPUT_DIR
  mv ./$SAMPLE_NAME".summary.txt" $OUTPUT_DIR/$SAMPLE_NAME".tin.summary.txt"
done
```

Take a look at the files ending in ".tin.summary.txt" in the output directory for the medTIN scores.

### Gene Body Plots

This function generates gene-body plots given the bam file and the annotation in bed format.

```{bash}
PROJ_DIR=../../
OUTPUT_DIR=$PROJ_DIR/results/2_mapping/rseqc_analysis
BAM_DIR=$PROJ_DIR/results/2_mapping/STAR_alignment
mkdir -p $OUTPUT_DIR

geneBody_coverage.py -r $PROJ_DIR/data/supplementary-files/Ensembl_R64_genes/genes.bed \
  -i $BAM_DIR/G1.bam,$BAM_DIR/GE2.bam,$BAM_DIR/GE4.bam \
  -o $OUTPUT_DIR/example 2> $OUTPUT_DIR/example.geneBody.err
```

Take a look at the output pdfs. Note the heatmaps are organised from sample with lowest skew at the top to sample with the highest skew at the bottom.

### Read Duplication

This script attempts to quantify the level of duplication present in the bam file. There are more sophisticated [visualisations](https://bioconductor.org/packages/release/bioc/vignettes/dupRadar/inst/doc/dupRadar.html) and [quantifications](https://gatk.broadinstitute.org/hc/en-us/articles/360037052812-MarkDuplicates-Picard-) for determining duplication rate in sequence alignment, but this is a simple alternative. It quantifies duplicates using two methods: 1) reads with the same sequence 2) reads with the same starting position in genome and the same splicing.

```{bash}
PROJ_DIR=../../
OUTPUT_DIR=$PROJ_DIR/results/2_mapping/rseqc_analysis
BAM_DIR=$PROJ_DIR/results/2_mapping/STAR_alignment
mkdir -p $OUTPUT_DIR

for BAM_FILE in $BAM_DIR/GE2.bam $BAM_DIR/GE4.bam; do
  SAMPLE_NAME=$(basename ${BAM_FILE%.bam})
  echo $SAMPLE_NAME
  
  read_duplication.py \
    -i $BAM_FILE -o $OUTPUT_DIR/$SAMPLE_NAME 2> $OUTPUT_DIR/$SAMPLE_NAME".dup.err"
done
```

If the sequencing quality is low, we would expect the number of duplicates quantified by the first method to lower than the second and vice versa.

### GC Content

This script calculates the GC content based on the reads. If the GC content deviates too much than the usual distribution for this species, then it might be indicative that certain genes are over-represented.

```{bash}
PROJ_DIR=../../
OUTPUT_DIR=$PROJ_DIR/results/2_mapping/rseqc_analysis
BAM_DIR=$PROJ_DIR/results/2_mapping/STAR_alignment
mkdir -p $OUTPUT_DIR

for BAM_FILE in $BAM_DIR/GE2.bam $BAM_DIR/GE4.bam; do
  SAMPLE_NAME=$(basename ${BAM_FILE%.bam})
  echo $SAMPLE_NAME
  
  read_GC.py \
    -i $BAM_FILE -o $OUTPUT_DIR/$SAMPLE_NAME 2> $OUTPUT_DIR/$SAMPLE_NAME".GC.err"
done
```

### Bam Stats

This script generates some summary stats in line with the "\_Log.final.out" output files we have looked at before. Compare some of the numbers to ensure they are the same.

```{bash}
PROJ_DIR=../../
OUTPUT_DIR=$PROJ_DIR/results/2_mapping/rseqc_analysis
BAM_DIR=$PROJ_DIR/results/2_mapping/STAR_alignment
mkdir -p $OUTPUT_DIR

for BAM_FILE in $BAM_DIR/GE2.bam $BAM_DIR/GE4.bam; do
  SAMPLE_NAME=$(basename ${BAM_FILE%.bam})
  echo $SAMPLE_NAME
  
  bam_stat.py \
    -i $BAM_FILE > $OUTPUT_DIR/$SAMPLE_NAME".stat.txt"
done
```

Beware the standard output here is piped to a file and this script does not generate any outputs by itself.

### Exercise #3

1.  Which of the above methods is expected to look different had used the full data rather than these sub-sampled fastqs? Assume the subsampling of reads from the original trimmed fastqs was random.
2.  Looking at just these outputs, does it look like we were able to remove issues related to sample GE4?

::: {.callout-note collapse="true" appearance="simple"}
## Solutions

1.  We only expect the read duplication plot to significantly change, since we are less likely to have reads which overlap completely either in sequence or alignment the less reads are present in the sample.
2.  Going off just these QC outputs, it appears as though trimming has largely removed problematic sequences from the sample. Otherwise, the percentage of uniquely aligning sequences would have presumably been lower, we'd have a higher mismatch rate, etc.
:::
