---
title: "Part 2: Mapping"
format:
  html:
    embed-resources: true
    toc: true
    toc-location: left
    toc-depth: 3
    title-block-banner: "#00A7FF"
css: style.css
editor: visual
bibliography: references.bib
---

```{r}
suppressPackageStartupMessages({
  library(tidyverse)
})
```

# Introduction

Welcome to our introductory RNA-seq course.

In this part of the course, we will be primarily working with yeast samples, initially sequenced and analyzed at the Functional Genomics Center ZÃ¼rich. We will be exploring this dataset thoroughly, starting with the QC discussed in the presentations. For this first part, we will be dealing with the full data. For later parts, such as the mapping module, subsets of the data will be used instead to save computational resources and allow for faster processing.

## Downloading the data

First, let's download the data. The script will download a tar file containing our fastq files, decompress it, and deposit the files into the folder `data/tmp/yeast_fastq_full`. To execute this script, press on the green arrow button (for all such bash scripts, we first switch to the root directory i.e. `/home/rstudio/work/rna-seq-course-feb2023` , so the locations of all output files is clearer).

```{bash}
CURR_DIR=$(pwd)
cd ../..

# First we make a directory to house our data
YEAST_DIR=data/tmp/yeast_fastq_full
mkdir -p $YEAST_DIR

# Download the data
cd $YEAST_DIR
curl -O https://fgcz-gstore.uzh.ch/public/RNASeqCourse/yeast_full.tar

# Extract data
tar -xvf yeast_full.tar
rm -f yeast_full.tar

# Back home
cd $CURR_DIR
```

The data should be downloaded into `data/tmp/yeast_fastq_full/`. To check this, run

```{bash}
ls -lh ../../data/tmp/yeast_fastq_full
```

You should see 9 files in this directory. 8 files ending in fastq.gz and one "dataset.tsv" file. The "dataset.tsv" file gives some details about the samples. Let's load this file now in R to see how it looks like.

```{r}
ds <- data.table::fread("../../data/tmp/yeast_fastq_full/dataset.tsv") %>% as_tibble()
ds
```

## Exercise #1

1.  How many groups of samples are there?

2.  What Library Prep Kit was used?

3.  What is the read count? Is this what we expect for RNA-seq?

4.  Is there information about the strandedness of the libraries?

::: {.callout-note appearance="simple" collapse="true"}
### Solutions

1.  2 groups: Glucose and GlycEth (i.e. Glucose+Ethanol)

2.  Lexogen mRNA Stranded Kit

3.  The samples vary between 5M to just under 20M reads. In general, we seek to get around 20M samples for bulk RNA-seq of human and mouse samples. Given that these are yeast samples and the corresponding genome is significantly smaller, even 5M reads is enough to get good results (see Count QC in chapter 3).

4.  The libraries are anti-sense.
:::

# FastQC & MultiQC

First, let's run FastQC. This tool was developed by Babraham Bioinformatics [@Andrews:2010tn] and is what we will primarily use for QC of our fastq files. In addition, we will run MultiQC [@ewels2016] which aims to aggregate outputs from tools like FastQC into a single report for easier viewing. Let's run these tools now. This process takes about 10 minutes on 8 cores.

```{bash}
#| class-output: scrolling

CURR_DIR=$(pwd)
cd ../..

# Make directories
PROCESSED_FASTQC=results/1_qc/fastqc
PROCESSED_MULTIQC=results/1_qc/multiqc
mkdir -p $PROCESSED_FASTQC $PROCESSED_MULTIQC

# Process with FastQC
/opt/FastQC/fastqc --extract -o $PROCESSED_FASTQC \
  -t 8 -a data/supplementary-files/adapter_list.txt --kmers 7 \
  data/tmp/yeast_fastq_full/*fastq.gz
  
# Combine result with multiqc
multiqc --outdir $PROCESSED_MULTIQC $PROCESSED_FASTQC

# Back home
cd $CURR_DIR
```

Assuming we are not carrying on with manual execution of fastp in the next section, run the following block to delete the raw data.

```{bash}
rm -rf ../../data/tmp/yeast_fastq_full
```

## Exersise #2

Take a look at the outputs in the "results/1_qc/fastqc" and "results/1_qc/multiqc" directory to answer the following questions.

1.  Did the pooling work well?
2.  What could be an explanation for the decrease in quality towards the ends of the reads?
3.  How does the per-base sequence content look for each sample?
4.  Do you think it makes sense to sequence longer based on these data?
5.  What would be a good method of preprocessing?

::: {.callout-note collapse="true" appearance="simple"}
## Solutions

1.  There were most likely some problems with the pooling. GE4 appears to be over-represented while other samples are comparatively underrepresented. This could be due to the sequencer type: some Illumina instruments can prefer shorter fragments during bridge amplification.
2.  This is a multi-faceted issue. It is a general artifact of Illumina sequencers on one hand, related towards the speed of sequencing and the longevity of the reagents. We sequenced on the NextSeq, which has a maximum read length of 150. On another, adapter content towards the 3' end of the read can negatively affect the performance.
3.  It looks as expected. GE4 however has an increase in the amount of Gs towards the end of the read. This is most likely due to very short fragment lengths (or adapter dimers) and the sequencer beginning to read past the adapter.
4.  No, the adapter content is already quite high for most of the samples. Sequencing longer fragments would not be worth the investment, most likely.
5.  Trimming off the adapter and removing the first few bases off the 5' end would remove most of the marking of bad quality from these samples, especially GE4.
:::

# FastqScreen

[FastqScreen](https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/_build/html/index.html) is a tool which aligns fastq files to a database of different genomes to determine from where the data originate. This can be used for a variety of purposes, such as for metagenomic characterisation, but we will use it as a QC tool to determine any potential sources of contamination.

Unfortunately, executing `fastq_screen` can take a significant amount of time even on a larger amount of resources than we have available in the course, so we will simply look at the results. The application is installed, however, and you can take a look at the arguments it would take if we were to execute it ourselves.

```{bash}
#| class-output: scrolling
/opt/fastq_screen_v0.14.0/fastq_screen -h
```

Let's download these results now.

```{bash}
CURR_DIR=$(pwd)
cd ../..

# Make directories
OUTPUT_DIR=results/1_qc/fastq_screen
mkdir -p $OUTPUT_DIR
cd $OUTPUT_DIR

curl -O https://fgcz-gstore.uzh.ch/public/RNASeqCourse/yeast_fastq_screen.html

# Back home
cd $CURR_DIR
```

# Preprocessing with `fastp`

In this section, we preprocess the fastqs to prepare them for alignment in the next chapter using fastp[@chen2018]. This command-line tool trims and quality-filters reads in the input fastqs and deposits the output into a new set of fastq files. fastp has many potential options that can be set depending on the requirements of the experiment, but we opt for fairly simple options here. Look over the script below to see what it does, but **do not execute it**. Depending on the resources, fastp can take a long time to execute for this number of samples (\~1 hr in this case), so we opt to rather download the outputs for use in the next chapter.

```{bash, eval=FALSE}
CURR_DIR=$(pwd)
cd ../..

FASTP_OUTDIR=results/1_qc/fastp
mkdir -p $FASTP_OUTDIR

# Start processing with fastp
for FASTQ in data/tmp/yeast_fastq_full/*_R1.fastq.gz
  do SAMPLE_NAME=$(basename ${FASTQ%_R1.fastq.gz})
  echo $SAMPLE_NAME
  /opt/fastp --in1 $FASTQ \
    --out1 $FASTP_OUTDIR/$SAMPLE_NAME"_trimmed_R1.fastq.gz" \
    --thread 4 --trim_front1 4 --trim_tail1 0 \
    --adapter_fasta data/supplementary-files/allIllumina-forTrimmomatic-20160202.fa \
    --max_len1 0 --max_len2 0 --trim_poly_x --average_qual 20 \
    --poly_x_min_len 10 --length_required 30 --compression 2 \
    2> $FASTP_OUTDIR/$SAMPLE_NAME"_preprocessing.log"
  rm -f $FASTQ
done

# Back home
cd $CURR_DIR
```

## Exercise #3

1.  What issues if any that you noticed in the FastQC output would be solved by using fastp with the arguments provided?
2.  Which sequences are provided for trimming?
3.  How could the sequence of operations of fastp affect trimming?

::: {.callout-note appearance="simple" collapse="true"}
### Solutions

1.  The adapter content in some of the samples

2.  The file with all sequences considered to be adapter provided here `data/supplementary-files/allIllumina-forTrimmomatic-20160202.fa` . This list is not exhaustive and may need to be expanded if your library prep in question uses an adapter not in the list.

3.  According to the documentation on GitHub, fastp performs trimming in the following order:

    ``` text
    1, UMI preprocessing (--umi)
    2, global trimming at front (--trim_front)
    3, global trimming at tail (--trim_tail)
    4, quality pruning at 5' (--cut_front)
    5, quality pruning by sliding window (--cut_right)
    6, quality pruning at 3' (--cut_tail)
    7, trim polyG (--trim_poly_g, enabled by default for NovaSeq/NextSeq data)
    8, trim adapter by overlap analysis (enabled by default for PE data)
    9, trim adapter by adapter sequence (--adapter_sequence, --adapter_sequence_r2. For PE data, this step is skipped if last step succeeded)
    10, trim polyX (--trim_poly_x)
    11, trim to max length (---max_len)
    ```

    This sequence of steps might not work for every application. As an example: If we know we need to trim bases after the 5' adapter, as might be the case in some types of library prep, one round of fastp processing will not be enough. We would need to run fastp once to perform adapter trimming and then run fastp again to trim off the remaining sequences at the 5'.
:::
